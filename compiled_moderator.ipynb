{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kiit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\kiit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (7.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\kiit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (2020.4.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\kiit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kiit\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (4.46.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    }
   ],
   "source": [
    "#Importing all necessary libraries\n",
    "!pip3 install nltk\n",
    "!pip3 install pylanguagetool\n",
    "!pip install pyspellchecker\n",
    "!pip install pymysql\n",
    "!pip install gensim\n",
    "!pip install textblob\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from pylanguagetool import api\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.parsing.preprocessing import remove_stopwords,stem_text,strip_tags\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "\n",
    "##############################################################################################################\n",
    "#Defining the spelling and grammer check \n",
    "\n",
    "def grammer_spelling_check(data):\n",
    "    sent=(sent_tokenize(data))\n",
    "    c1=1\n",
    "    for i in sent:\n",
    "        c2=1\n",
    "        word = (word_tokenize(i))\n",
    "        for j in word:\n",
    "            if(j==\".\"*len(j)):\n",
    "                print(\"Repitition of punctuation in position \"+str(c2) +\" in line \"+str(c1))\n",
    "            else:\n",
    "                if(len(j)==1 and ((j<'a' or j>'z') and (j<'A' or j>'Z')) and ((c2-1)!=0)):\n",
    "                    if(word[c2-2]!=\"ouch\" and word[c2-2]!=\"aah\" and word[c2-2]!=\"aha\" and word[c2-2]!=\"oho\" and word[c2-2]!=\"hurray\" and word[c2-2]!=\"alas\" and word[c2-2]!=\"shit\" and word[c2-2]!=\"hey\" and word[c2-2]!=\"hi\" and word[c2-2]!=\"huh\"):\n",
    "                        print(\"Position of punctuation is not justified in position \"+str(c2) +\" in line \"+str(c1))\n",
    "                    else:\n",
    "                        if((c2-1)!=(len(word)-1)):\n",
    "                            if(word[c2-1]==word[c2]):\n",
    "                                print(\"Repeatition of punctuation in position \"+str(c2) +\" in line \"+str(c1))\n",
    "                else:\n",
    "                    #eikhane jabotio ja ache dhokate hbe\n",
    "                    if(spell.correction(j)!=j):\n",
    "                        print(\"Possible spelling mistake in position \"+str(c2)+\" in line \"+str(c1))#+\" probable word \"+spell.correction(j))\n",
    "                    else:\n",
    "                        if(TextBlob(j).correct()!=j):\n",
    "                            print(\"Possible spelling mistake in position \"+str(c2)+\" in line \"+str(c1))#+\" probable word \"+spell.correction(j))\n",
    "\n",
    "            c2=c2+1\n",
    "        check=api.check(i,api_url='https://languagetool.org/api/v2/',lang='en-US', )['matches']\n",
    "        for i in check:\n",
    "            if(i[\"message\"][0:27]==\"Possible spelling mistake\"):\n",
    "                print(i[\"message\"] + \" in line \"+str(c1))\n",
    "        c1=c1+1\n",
    "\n",
    "##############################################################################################################\n",
    "        \n",
    "        \n",
    "#function for finding similarity\n",
    "def similarity(X,Y):\n",
    "        X=str(X)\n",
    "        # Program to measure similarity between  \n",
    "        # two sentences using cosine similarity. \n",
    "        X=str(X)\n",
    "        Y=str(Y)\n",
    "\n",
    "        X = X.lower() \n",
    "        Y = Y.lower() \n",
    "\n",
    "        # tokenization \n",
    "        X_list = word_tokenize(X)  \n",
    "        Y_list = word_tokenize(Y) \n",
    "\n",
    "        # sw contains the list of stopwords \n",
    "        sw = stopwords.words('english')  \n",
    "        l1 =[];l2 =[] \n",
    "\n",
    "        # remove stop words from string \n",
    "        X_set = {w for w in X_list if not w in sw}  \n",
    "        Y_set = {w for w in Y_list if not w in sw} \n",
    "\n",
    "        # form a set containing keywords of both strings  \n",
    "        rvector = X_set.union(Y_set)  \n",
    "        for w in rvector: \n",
    "            if w in X_set: l1.append(1) # create a vector \n",
    "            else: l1.append(0) \n",
    "            if w in Y_set: l2.append(1) \n",
    "            else: l2.append(0) \n",
    "        c = 0\n",
    "\n",
    "        # cosine formula  \n",
    "        for i in range(len(rvector)): \n",
    "            c+= l1[i]*l2[i] \n",
    "\n",
    "        if(float((sum(l1)*sum(l2))**0.5) ==0.0):\n",
    "            return(0)\n",
    "        else:\n",
    "            cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "            return cosine\n",
    "        \n",
    "##############################################################################################################\n",
    "\n",
    "#download the edx dataset\n",
    "edx=pd.read_csv(\"EDX_data.csv\")\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "#function for retrieving text from html scripts\n",
    "def data_cleaning(data,empty_list):\n",
    "    for doc in data:\n",
    "        #html=strip_tags(str(doc))\n",
    "        html=BeautifulSoup(str(doc), 'lxml').get_text()\n",
    "        dig=re.sub(\" \\d+\", \" \", html)\n",
    "        sp_char=re.sub('[^A-Za-z0-9]+', ' ', dig)\n",
    "        empty_list.append(sp_char)\n",
    "        \n",
    "        \n",
    "#Downloading our database courses from location\n",
    "df=pd.read_csv(\"Courses.csv\")\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "#Formation of our main dataset\n",
    "\n",
    "df1=pd.DataFrame()\n",
    "df1[\"course title\"]=df[\"course_title\"]\n",
    "df1[\"course description\"]=df[\"course_description\"]\n",
    "df1[\"course subtitle\"]=df[\"course_subtitle\"]\n",
    "df1[\"course id\"]=df[\"course_id\"]\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#Extract and take the course id as input and extract the course description and title for only that course for validation with ideal\n",
    "id=\"47215856678036\"\n",
    "course_description=\"\"\n",
    "course_title=\"\"\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "\n",
    "#Cleaning the dataset\n",
    "c=0\n",
    "for i in df1[\"course id\"]:\n",
    "    if(id==i):\n",
    "        course_description = df1[\"clean course description\"][c]\n",
    "        course_title = df1[\"course title\"][c]\n",
    "    c=c+1\n",
    "    \n",
    "############################################################################################################   \n",
    "    \n",
    "#Validation checking caller module\n",
    "c=0\n",
    "flag=0\n",
    "for i in edx[\"Name\"]:\n",
    "    if(similarity(course_title,i)>0.45 and similarity(course_description,edx[\"Description\"][c])>0.45):\n",
    "        tttt=0\n",
    "    elif(similarity(course_title,i)>0.45 and similarity(course_description,edx[\"Description\"][c])<0.45):\n",
    "        flag=1\n",
    "        print(\"some changes are required. For demo: \")\n",
    "        print(edx[\"Description\"][c])\n",
    "if(flag == 0):\n",
    "    print(\"No changes required!!\")    \n",
    "    \n",
    "##############################################################################################################\n",
    "    \n",
    "#Calling spell_gram check \n",
    "\n",
    "for i in df1[\"course_description\"]:\n",
    "    grammer_spelling_check(i)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
